{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a5db508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5f1b8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69cf8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"getomni-ai/ocr-benchmark\")\n",
    "\n",
    "print(type(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8abef089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0896faa",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_models = {} # {model_name: handler_func}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0490333",
   "metadata": {},
   "source": [
    "### apple-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1ae015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = './models/apple-ocr/src'\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from apple_ocr import ocr\n",
    "\n",
    "def apple_ocr_handler(image):\n",
    "  def parse_apple_ocr_result(data, w, h):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "      bbox = instance[2]\n",
    "      origin_x_normalized = bbox[0]\n",
    "      origin_y_normalized = bbox[1]\n",
    "      width_normalized = bbox[2]\n",
    "      height_normalized = bbox[3]\n",
    "\n",
    "      x1 = origin_x_normalized * w\n",
    "      y1 = origin_y_normalized * h\n",
    "      x2 = x1 + (width_normalized * w)\n",
    "      y2 = y1 + (height_normalized * h)\n",
    "      x1, y1, x2, y2 = np.int32(round(x1)), np.int32(round(y1)), np.int32(round(x2)), np.int32(round(y2))\n",
    "\n",
    "      output.append({\n",
    "        'text': instance[0],\n",
    "        'confidence': instance[1],\n",
    "        'bbox': [\n",
    "            [x1, y2], # top left\n",
    "            [x2, y2], # top right\n",
    "            [x1, y1], # bottom left\n",
    "            [x2, y1]  # bottom right\n",
    "          ]\n",
    "      })\n",
    "    return output\n",
    "\n",
    "  apple_ocr = ocr.OCR(image=image)\n",
    "  image_width, image_height = image.size\n",
    "\n",
    "  start_time = time.time()\n",
    "  df = apple_ocr.recognize()\n",
    "  end_time = time.time()\n",
    "  runtime = end_time - start_time\n",
    "\n",
    "  # Before parsing:\n",
    "  # [\n",
    "  #   (\n",
    "  #     text: str,\n",
    "  #     confidence: float,\n",
    "  #     [bbox.origin.x: float, bbox.origin.y: float, bbox.size.width: float, bbox.size.height: float]\n",
    "  #   ), ...\n",
    "  # ]\n",
    "  # Apple:\n",
    "  # bbox: The coordinates of the bounding box are normalized to the dimensions of the processed image, with the origin at the lower-left corner of the image.\n",
    "  # confidence: A normalized confidence score for the text recognition result.\n",
    "  out = apple_ocr.data\n",
    "  return parse_apple_ocr_result(out, image_width, image_height), runtime\n",
    "\n",
    "ocr_models['apple-ocr'] = apple_ocr_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792145f",
   "metadata": {},
   "source": [
    "### Easy-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dec2dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "def easyocr_handler(image):\n",
    "  def parse_easyocr_result(data):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "      output.append(\n",
    "        {\n",
    "          'text': instance[1],\n",
    "          'confidence': instance[2],\n",
    "          'bbox': instance[0]\n",
    "        }\n",
    "      )\n",
    "    return output\n",
    "\n",
    "  image = np.array(image)\n",
    "  reader = easyocr.Reader(['en'])  # specify language\n",
    "  # Before parsing:\n",
    "  # [\n",
    "  #   (\n",
    "  #     [[x1, y1], [x2, y2], [x3, y3], [x4, y4]],\n",
    "  #     text: str, \n",
    "  #     confidence: np.float64\n",
    "  #   ), ...\n",
    "  # ]\n",
    "  start_time = time.time()\n",
    "  results = reader.readtext(image)\n",
    "  end_time = time.time()\n",
    "  runtime = end_time - start_time\n",
    "  return parse_easyocr_result(results), runtime\n",
    "\n",
    "ocr_models['easy-ocr'] = easyocr_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0936ac",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6e8cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== apple-ocr ===========\n",
      "Runtime: 0.6084878444671631\n",
      "0            Staff Shift Schedule\n",
      "1    Fort Bradlv Medical Center -\n",
      "2      Week of September 27, 2025\n",
      "3                        Employee\n",
      "4                Courtney Lebsack\n",
      "5                     Linda Lesch\n",
      "6                   Roberto Stehr\n",
      "7                Horace Gleichner\n",
      "8                    Stella Fadel\n",
      "9                Jared Leannon II\n",
      "Name: text, dtype: object\n",
      "=========== easy-ocr ===========\n",
      "Runtime: 4.683197975158691\n",
      "0          Staff Shift Schedule\n",
      "1                          Fort\n",
      "2         Bradly Medical Center\n",
      "3    Week of September 27, 2025\n",
      "4                      Employee\n",
      "5                            ID\n",
      "6                    Department\n",
      "7                        Sat 27\n",
      "8                        Sun 28\n",
      "9                        Mon 29\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "img = data[99]['image']\n",
    "for name, handler in ocr_models.items():\n",
    "  out, runtime = handler(img)\n",
    "  df = pd.DataFrame(out)\n",
    "  print(f'=========== {name} ===========\\nRuntime: {runtime}')\n",
    "  print(df['text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b085f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
